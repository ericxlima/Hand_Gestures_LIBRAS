# Machine Learning for Hand Gesture Recognition Applied to LIBRAS (Brazilian Sign Language)

## An application that uses Machine Learning capable of judging with precision if the gesture made with the hand is ornot a vowel of the Brazilian Sign Language, through a webcam.

#
###  Demostration 🤌
<img src="media/demostration.gif" width="600px;" alt="Eric"/>

#
### Links 🔗
- 📃[__Clique aqui__](docs/docs_PT.pdf)  para ler o relatório 🇧🇷
- 📃[__Click here__](docs/docs_EN.pdf) to read the report 🇺🇸
- 📽[__Click here__](https://youtu.be/mJnmJwxQFNU)  to view the presentation 🇧🇷 🇺🇸


#
### To Run 💻
- In your shell:
```bash
#  Clone this repository:
git clone https://github.com/ericxlima/Hand_Gestures_LIBRAS.git

#  Entry in Directory:
cd Hand_Gestures_LIBRAS

        #  Activate your virtual environment

#  Install all requirements
pip3 install -r requirements.txt

#  Run the application
python3 main.py

```

#
###  Keys ⌨️
|  Key  |  Description |
| --- | --- |
| Q | Quit Window |
| space | Classify Gesture |
| A | Add gesture to label "A" of the Training Database |
| E | Add gesture to label "E" of the Training Database |
| I | Add gesture to label "I" of the Training Database |
| O | Add gesture to label "O" of the Training Database |
| U | Add gesture to label "U" of the Training Database |



#
##  Authors 👥
| <img style="border-radius: 50%;" src="https://avatars.githubusercontent.com/u/58092119?v=4" width="120px;" alt="Eric"/> | <img style="border-radius: 50%;" src="https://avatars.githubusercontent.com/u/60946868?v=4" width="120px;" alt="Michel"/> |
| :----: | :----: |
| [Eric de Lima](https://github.com/ericxlima) | [Michel Leonidas](https://github.com/OnLeonidas) |