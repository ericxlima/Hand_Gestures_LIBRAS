# Machine Learning for Hand Gesture Recognition Applied to LIBRAS (Brazilian Sign Language)

## An application that uses Machine Learning capable of judging with precision if the gesture made with the hand is ornot a vowel of the Brazilian Sign Language, through a webcam.

#
###  Demostration ğŸ¤Œ
<img src="media/demostration.gif" width="600px;" alt="Eric"/>

#
### Links ğŸ”—
- ğŸ“ƒ[__Clique aqui__](docs/docs_PT.pdf)  para ler o relatÃ³rio ğŸ‡§ğŸ‡·
- ğŸ“ƒ[__Click here__](docs/docs_EN.pdf) to read the report ğŸ‡ºğŸ‡¸
- ğŸ“½[__Click here__](https://youtu.be/mJnmJwxQFNU)  to view the presentation ğŸ‡§ğŸ‡· ğŸ‡ºğŸ‡¸


#
### To Run ğŸ’»
- In your shell:
```bash
#  Clone this repository:
git clone https://github.com/ericxlima/Hand_Gestures_LIBRAS.git

#  Entry in Directory:
cd Hand_Gestures_LIBRAS

        #  Activate your virtual environment

#  Install all requirements
pip3 install -r requirements.txt

#  Run the application
python3 main.py

```

#
###  Keys âŒ¨ï¸
|  Key  |  Description |
| --- | --- |
| Q | Quit Window |
| space | Classify Gesture |
| A | Add gesture to label "A" of the Training Database |
| E | Add gesture to label "E" of the Training Database |
| I | Add gesture to label "I" of the Training Database |
| O | Add gesture to label "O" of the Training Database |
| U | Add gesture to label "U" of the Training Database |



#
##  Authors ğŸ‘¥
| <img style="border-radius: 50%;" src="https://avatars.githubusercontent.com/u/58092119?v=4" width="120px;" alt="Eric"/> | <img style="border-radius: 50%;" src="https://avatars.githubusercontent.com/u/60946868?v=4" width="120px;" alt="Michel"/> |
| :----: | :----: |
| [Eric de Lima](https://github.com/ericxlima) | [Michel Leonidas](https://github.com/OnLeonidas) |